@misc{2019RGBDepacking,
    author = {test},
   month = {3},
   title = {RGB to YUV format conversion and inverse conversion method and circuit for depth packing and depacking},
   url = {https://eds.s.ebscohost.com/eds/detail/detail?vid=6&sid=8ed0222f-b410-4a00-8cf0-aee5fe6197da\%40redis&bdata=JnNpdGU9ZWRzLWxpdmUmc2NvcGU9c2l0ZQ\%3d\%3d#db=edspgr&AN=edspgr.10242646},
   year = {2019},
   urldate = {2023-05-23}, 
}
@web_page{Menasco2022MethodFormat,
   author = {Esq. Timothy W. Menasco and Harter Secrest & Emery LLP},
   journal = {Method, device, and storage medium for converting image from raw format to RGB format},
   month = {10},
   title = {Method, device, and storage medium for converting image from raw format to RGB format},
   url = {https://eds.s.ebscohost.com/eds/detail/detail?vid=7&sid=7b3e4dd2-262f-4493-bf40-8070e5274b3a\%40redis&bdata=JnNpdGU9ZWRzLWxpdmUmc2NvcGU9c2l0ZQ\%3d\%3d#db=edspgr&AN=edspgr.11470294},
   year = {2022},
   urldate = {2023-05-23}, 
}
@web_page{dji_flightcontroller,
   author = {DJI},
   title = {Mobile SDK Flightcontroller},
   url = {https://developer.dji.com/api-reference/android-api/Components/FlightController/DJIFlightController.html?search=flightcon&i=0&},
   urldate = {2023-05-15}, 
}
@generic{mobilenet,
   author = {Jonathan Huang, et. al},
   title = {Speed/accuracy trade-offs for modern convolutional object detectors},
   year = {2017},
   urldate = {2023-05-15},
}
@computer_program{githubmobilesdk,
   author = {DJI},
   journal = {Github},
   publisher = {Github},
   title = {Mobile-SDK-Tutorials},
   url = {https://github.com/DJI-Mobile-SDK-Tutorials},
   urldate = {2023-05-15},
}
@computer_program{azGithubMobil,
   author = {AstaZero},
   publisher = {Github},
   title = {A Demo for using DJI Mobile SDK to create a Waypoint Mission App using Google Map.},
   url = {https://github.com/RI-SE/Android-GSDemo-GoogleMap},
   urldate = {2023-05-15},
}
@misc{VOLVOSAFETY,
   author = {Volvo Car Corporation},
   title = {Aiming for zero},
   url = {https://group.volvocars.com/company/safety-vision},
   year = {2020},
   urldate = {2023-05-15},
}
@misc{ssd,
   author = {Wei Liu and Dragomir Anguelov and Dumitru Erhan and Christian Szegedy and Scott Reed and Cheng-Yang Fu and Alexander C Berg},
   doi = {10.1007/978-3-319-46448-0_2},
   journal = {Computer Vision  ECCV 2016},
   pages = {21-37},
   publisher = {Springer International Publishing},
   title = {SSD: Single Shot MultiBox Detector},
   url = {https://doi.org/10.1007\%2F978-3-319-46448-0_2},
   year = {2016},
}
@misc{tflite,
   author = {TensorFlow},
   title = {Post-training quantization  |  TensorFlow Lite},
   url = {https://www.tensorflow.org/lite/performance/post_training_quantization},
   urldate = {2023-05-15},
}
@web_page{djisdkdemoish,
   author = {DJI},
   title = {Application Activation and Aircraft Binding - DJI Mobile SDK Documentation},
   url = {https://developer.dji.com/mobile-sdk/documentation/android-tutorials/ActivationAndBinding.html},
   urldate = {2023-05-15},
}
@article{cnnförklarning,
   abstract = {Convolutional neural network (CNN), a class of artificial neural networks that has become dominant in various computer vision tasks, is attracting interest across a variety of domains, including radiology. CNN is designed to automatically and adaptively learn spatial hierarchies of features through backpropagation by using multiple building blocks, such as convolution layers, pooling layers, and fully connected layers. This review article offers a perspective on the basic concepts of CNN and its application to various radiological tasks, and discusses its challenges and future directions in the field of radiology. Two challenges in applying CNN to radiological tasks, small dataset and overfitting, will also be covered in this article, as well as techniques to minimize them. Being familiar with the concepts and advantages, as well as limitations, of CNN is essential to leverage its potential in diagnostic radiology, with the goal of augmenting the performance of radiologists and improving patient care.},
   author = {Rikiya Yamashita and Mizuho Nishio and Richard Kinh Gian Do and Kaori Togashi},
   doi = {10.1007/s13244-018-0639-9},
   issn = {1869-4101},
   issue = {4},
   journal = {Insights into Imaging},
   pages = {611-629},
   title = {Convolutional neural networks: an overview and application in radiology},
   volume = {9},
   url = {https://doi.org/10.1007/s13244-018-0639-9},
   year = {2018},
}
@generic{cnnbild,
   abstract = {https://openverse.org/image/8e83a90d-12e3-402f-a00a-b66f600cbd10?q=neural\%20network},
   author = {Cecbur},
   title = {Convolutional Neural Network with Color Image Filter},
   url = {https://openverse.org/image/8e83a90d-12e3-402f-a00a-b66f600cbd10?q=neural\%20network},
}
@web_page{TransportstyrelsenDronesAircraft,
   author = {Transportstyrelsen},
   title = {Drones – unmanned aircraft},
   url = {https://www.transportstyrelsen.se/en/aviation/Aircraft/drones--unmanned-aircraft/},
   urldate = {2023-05-12},
}
@web_page{DJI_stockholm,
   author = {DJI Stockholm},
   title = {DJI Mavic},
   url = {https://djistockholm.se/kategori/dji-mavic-main/},
   urldate = {2023-05-12},
}
@web_page{Verc2018Close-upDrone,
   author = {Marco Verc},
   journal = {Creative Commons 2.0},
   month = {9},
   title = {Close-up of DJI Mavic 2 Zoom drone},
   url = {https://www.flickr.com/photos/149561324@N03/44418213012},
   year = {2018},
   urldate = {2023-05-12},
}
@article{PublicationofficeoftheEuropeanUnion2019CommissionSystems,
   author = {Publication office of the European Union},
   journal = {EUR-Lex},
   title = {Commission Delegated Regulation (EU) 2019/945 on unmanned aircraft systems and on third-country operators of unmanned aircraft systems},
   url = {http://data.europa.eu/eli/reg_del/2019/945/2020-08-09},
   year = {2019},
}
@web_page{DJIDJIActiveTrackOperator,
   author = {DJI},
   title = {DJI Mobile SDK Documentation | ActiveTrackOperator},
   url = {https://developer.dji.com/api-reference/android-api/Components/Missions/DJIActiveTrackMissionOperator.html},
   urldate = {2023-05-12},
}
@web_page{DJIDJICodecManager,
   author = {DJI},
   title = {DJI Mobile SDK Documentation | DJICodecManager},
   url = {https://developer.dji.com/api-reference/android-api/Components/CodecManager/DJICodecManager.html},
   urldate = {2023-05-12},
}
@computer_program{githubTensorFlowApp,
   author = {mrinalTheCode},
   journal = {Github},
   title = {Android app using Tensorflow Lite API for object detection},
   url = {https://github.com/mrinalTheCoder/ObjectDetectionApp},
   urldate = {2023-05-12},
}
@web_page{COCOConsortiumCommonContext,
   author = {COCO Consortium},
   title = {Common Objects in Context},
   url = {https://cocodataset.org/#home},
   urldate = {2023-05-12}
}
@computer_program{TensorFlow2021TensorFlowZoo,
   author = {TensorFlow},
   journal = {Github},
   title = {TensorFlow 1 Detection Model Zoo},
   url = {https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md#mobile-models},
   year = {2021},
   urldate = {2023-05-12},
}
@web_page{AtlassianTrello,
   author = {Atlassian},
   title = {Trello},
   url = {https://trello.com},
   urldate = {2023-05-11},
}
@web_page{a13_chipset,
   author = {Samsung},
   title = {Exynos 850 | Mobile Processor | Samsung Semiconductor Global},
   url = {https://semiconductor.samsung.com/processor/mobile-processor/exynos-850/},
   year = {2023},
   urldate = {2023-05-11},
}
@report{Douglas1973ALGORITHMSCARICATURE,
   author = {David Douglas and Thomas K Peucker},
   city = {Ottawa},
   institution = {University of Ottawa/Simon Fraser University, British Columbia },
   month = {12},
   pages = {112-122},
   title = {ALGORITHMS FOR THE REDUCTION OF THE NUMBER  OF POINTS REQUIRED TO REPRESENT A DIGITIZED  LINE OR ITS CARICATURE},
   year = {1973},

}
@web_page{EuroNCAPTheProgramme,
   author = {Euro NCAP},
   title = {The European New Car Assessment Programme},
   url = {https://www.euroncap.com/en},
   urldate = {2023-03-11},
}
@web_page{AFlickr,
   title = {A Short Comparison Between Apple iPhone 12 Pro and Samsung… | Flickr},
   url = {https://www.flickr.com/photos/188421848@N07/49892254482},
   urldate = {2023-05-11},
}
@generic{iso22133,
   journal = {ISO/TC 22/SC 33 Vehicle dynamics, chassis components and driving automation systems testing},
   title = {ISO/TS 22133:2023 - Road vehicles — Test object monitoring and control for active safety and automated/autonomous vehicle testing — Functional requirements, specifications and communication protocol},
   url = {https://www.iso.org/standard/78970.html},
   year = {2023},
}
@article{AntchevaGUIDELINESGUI,
   abstract = {Designing a usable, visually-attractive Graphical User Interface (GUI) is somewhat more difficult than appears at first glance. It adds quality to the application only if it reflects the needs and capabilities of the users within the hardware and software constraints. The basic guidelines that constitute an intuitive and good user interface are discussed in this paper.},
   author = {I Antcheva and R Brun and F Rademakers and Geneva Switzerland},
   title = {GUIDELINES FOR DEVELOPING A GOOD GUI},
}
@article{Pak2018ARecognition,
   abstract = {Deep learning has been the core topic in machine learning and convolutional neural network is one of the most prominent approaches. Convolutional neural network has won numerous competitions in recent years. It has outstanding results in image recognition. We review the different deep learning approaches which have been used in the field of image classification and localization.},
   author = {Myeongsuk Pak and Sanghoon Kim},
   doi = {10.1109/CAIPT.2017.8320684},
   isbn = {9781538606001},
   journal = {Proceedings of the 2017 4th International Conference on Computer Applications and Information Processing Technology, CAIPT 2017},
   keywords = {convolutional neural network,deep learningt,image recognition},
   month = {3},
   pages = {1-3},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {A review of deep learning in image recognition},
   volume = {2018-January},
   year = {2018},
}
@web_page{AstaZeroAboutUs,
   author = {AstaZero},
   title = {About us},
   url = {https://www.astazero.com/en/about-us/},
   urldate = {2023-05-05},
}
@article{speed_euro_ncap,
   author = {Euro NCAP},
   title = {TEST PROTOCOL-SPEED ASSIST SYSTEMS},
   year = {2017},
}
@article{Ahamed2015InspirationD,
   abstract = {This paper is based on the notion that the elemental modules of knowledge (K) are exchanged or transferred by virtual exchanges of verb functions (VF's) between noun objects or knowledge centric objects (KCOs). In order to be practical and concurrently meaningful, we explore the concepts in this theory whereby the protocol for the knowledge path of smaller kco's is in the physical domain and the larger knowledge centric object (KCO) is transported by imagery, similarities, parallelisms, and inspirations. One or subsequent socio-psychological pathways (memory flashback , trigger-images, look, glance, gesture, etc.) confirm the knowledge exchange is imminent and then an "image" of a large body of knowledge (KCO) gets subconsciously formed by the receptor whereby bulk of the content is exchanged between the donor(s) and recipient(s) or vice versa. This image of the KCO is transferred, processed, reinforced and refined. For example, love at first sight is another name for this mystic process. As another example, two scientists can communicate an enormous amount of information significant and beneficial to each other, in a short time by pre-assigned symbols, notations, equations, and even looks, signs or a gesture. The resulting image is a constructive combination of the perceived image (as a seed or nucleus) and the supplementary image(s) from the receptor's own knowledge banks. We hasten to add that cruelty and violence can also be transferred thus. For example, a tiny insignificant nation can induce hate and aggression against other nations by distorting images fed to a much larger more powerful nation. Such examples are much too prevalent in history. Knowledge space becomes staggeringly more complex than the physical space. The order of complexity becomes at least fourfold because every noun-object (n), verb-function (v) and their combination (*) are unique, furthermore all three depend on the X, Y, Z, t, coordinates in socially and culture. Hence, it becomes necessary to limit the size of kunatum to "sensible" size and to be practical. Initially, it can be limited to most useful noun objects and verb functions. Two examples follow. In its practical format, a kunatum of knowledge can be stated as (food (n), eat (v), restaurant (x, y, z), date and time (t)). At the other extreme, a cosmic kunatum can be stated as (space-ship A (n), explore (v), coordinates-Planet B (x, y, z), cosmic calendar date and time (t)). The need to be practical and limit the programming complexity, it becomes a necessity to deal with kunatized knowledge within the realm of computation. Even so, the content of the knowledge so gathered (i.e., the food eaten in the restaurant or the data collected by the space ship) is not communicated. The flow of the entirety of knowledge needs a larger number of smaller kunata (kco's) to be complete within the global-kunata of knowledge (or KCO)},
   author = {Syed V Ahamed and Sonya M Ahamed},
   issue = {5},
   journal = {Journal of Multidisciplinary Engineering Science and Technology (JMEST)},
   keywords = {Knowledge Centric Objects,Knowledge Flow,Kuanta of Knowledge,Object-Object Communication},
   pages = {3159-3199},
   title = {Inspiration Flow Theory of Knowledge (D)},
   volume = {2},
   url = {www.jmest.org},
   year = {2015},
}
@web_page{WaypointMission,
   author = {DJI},
   title = {DJI Mobile SDK Documentation | WaypointMission},
   url = {https://developer.dji.com/api-reference/android-api/Components/Missions/DJIWaypointMission.html},
   urldate = {2023-05-04},
   year = {2022},
}
@computer_program{AstaZero2023ATOS:Systems.,
   author = {AstaZero},
   month = {3},
   publisher = {Github},
   title = {ATOS: ROS2 based platform for coordinating tests of autonomous vehicles and their surrounding systems.},
   url = {https://github.com/RI-SE/ATOS},
   urldate = {2023-04-29},
   year = {2023},
}
@web_page{Android,
   author = {Android Developers},
   title = {Activity},
   url = {https://developer.android.com/reference/android/app/Activity},
   urldate = {2023-04-28},
}
@web_page{TestDriven.ioWhatDevelopment,
   author = {TestDriven.io},
   title = {What is Test-Driven Development?},
   url = {https://testdriven.io/test-driven-development/},
   urldate = {2023-04-04},
}
@web_page{DJI2018MavicDJI,
   author = {DJI},
   title = {Mavic 2 - DJI},
   url = {https://www.dji.com/se/mavic-2},
   urldate = {2023-02-07},
   year = {2018},
}
@article{EuroNCAP2022EuroMobility,
   author = {Euro NCAP},
   month = {11},
   title = {Euro NCAP vision 2030: A Safer Future for Mobility},
   url = {https://www.euroncap.com/en/press-media/press-releases/euro-ncap-vision-2030-a-safer-future-for-mobility/},
   urldate = {2023-01-31},
   year = {2022},
}
@web_page{DJI2021MAVICMANUAL,
   author = {DJI},
   month = {4},
   pages = {15},
   title = {MAVIC 2 ENTERPRISE SERIES USER MANUAL},
   url = {https://dl.djicdn.com/downloads/Mavic_2_Enterprise/20210413/Mavic_2_Enterprise_Series_User_Manual-EN.pdf},
   urldate = {2023-01-31},
   year = {2021},
}
@web_page{OpenCVteam2023OpenCV,
   author = {OpenCV team},
   title = {openCV},
   url = {https://opencv.org/},
   year = {2023},
   urldate = {2023-01-31},
}
@article{EuroNCAP2021FILMPROTOCOL,
   abstract = {Version 1.3.1},
   author = {Euro NCAP},
   month = {11},
   title = {FILM & PHOTO PROTOCOL},
   url = {https://cdn.euroncap.com/media/67257/euro-ncap-film-and-photo-protocol-v131.pdf},
   urldate = {2023-01-31},
   year = {2021},
}
@article{EuroNCAP2022TESTImplementationb,
   abstract = {Version 4.3},
   author = {Euro NCAP},
   month = {11},
   title = {TEST PROTOCOL-AEB/LSS VRU systems Implementation},
   url = {https://cdn.euroncap.com/media/75436/euro-ncap-aeb-lss-vru-test-protocol-v43.pdf},
   year = {2022},
}
@article{EuroNCAP2022TESTImplementation,
   abstract = {Version 4.1.1},
   author = {Euro NCAP},
   month = {11},
   title = {TEST PROTOCOL-AEB Car-to-Car systems Implementation},
   url = {https://cdn.euroncap.com/media/75439/euro-ncap-aeb-c2c-test-protocol-v411.pdf},
   year = {2022},
}
@article{EuroNCAP2022TESTImplementationc,
   abstract = {Version 4.2},
   author = {Euro NCAP},
   month = {11},
   title = {TEST PROTOCOL-Lane Support Systems Implementation},
   url = {https://cdn.euroncap.com/media/75440/euro-ncap-lss-test-protocol-v42.pdf},
   year = {2022},
   urldate = {2023-01-31},
}
@web_page{AmitKatwala2018TheAddiction,
   abstract = {https://www.wired.co.uk/article/lithium-batteries-environment-impact},
   author = {Amit Katwala},
   journal = {Wired},
   month = {5},
   title = {The spiralling environmental cost of our lithium battery addiction},
   year = {2018},
   urldate = {2023-01-31},
}
@web_page{BauerSophie2020Explainer:Industry,
   author = {Bauer Sophie},
   journal = {Diálogo Chino},
   month = {12},
   title = {Explainer: the opportunities and challenges of the lithium industry},
   url = {https://dialogochino.net/en/extractive-industries/38662-explainer-the-opportunities-and-challenges-of-the-lithium-industry/},
   year = {2020},
   urldate = {2023-01-31},
}
@report{EuroNCAP2022EuropeanNCAP,
   author = {Euro NCAP},
   month = {11},
   title = {European New Car Assessment Programme (Euro NCAP)},
   year = {2022},
}
